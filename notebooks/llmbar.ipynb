{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/gws/nopw/j04/ai4er/users/maiush/LP-as-a-Judge/cached\"\n",
    "\n",
    "import os, pickle\n",
    "import torch as t\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from lpaaj.data import LLMBar\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "models = [\"gemma-2-2b\", \"gemma-2-9b\", \"gemma-2-27b\", \"llama-3.1-8b\", \"llama-3.1-70b\"]\n",
    "model_titles = {\n",
    "    \"gemma-2-2b\": \"Gemma 2 2B\",\n",
    "    \"gemma-2-9b\": \"Gemma 2 9B\",\n",
    "    \"gemma-2-27b\": \"Gemma 2 27B\",\n",
    "    \"llama-3.1-8b\": \"Llama 3.1 8B\",\n",
    "    \"llama-3.1-70b\": \"Llama 3.1 70B\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [f for f in os.listdir(PATH) if \"llmbar\" in f]\n",
    "subsets = [f.split(\"-\")[1] for f in dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:47<00:00, 16.71s/it]\n",
      "100%|██████████| 10/10 [01:22<00:00,  8.24s/it]\n",
      " 90%|█████████ | 9/10 [01:49<00:14, 14.07s/it]/gws/nopw/j04/ai4er/users/maiush/miniforge3/envs/finetuning/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "100%|██████████| 10/10 [02:10<00:00, 13.02s/it]\n",
      "100%|██████████| 10/10 [00:39<00:00,  3.96s/it]\n",
      "100%|██████████| 10/10 [00:32<00:00,  3.30s/it]\n"
     ]
    }
   ],
   "source": [
    "for model in models:    \n",
    "    results = pd.DataFrame(columns=[\"subset\", \"method\", \"f1\"])\n",
    "    for subset in tqdm(subsets):\n",
    "        # load data (and labels)\n",
    "        data = LLMBar(\n",
    "            subset=subset,\n",
    "            task=\"compare\",\n",
    "        )\n",
    "        # prompting\n",
    "        preds = pickle.load(\n",
    "            open(\n",
    "                f\"{PATH}/llmbar-{subset}/{model}/compare.pkl\",\n",
    "                \"rb\"\n",
    "            )\n",
    "        )\n",
    "        score = f1_score(data.labels, preds, average=\"weighted\", labels=[1, 2])\n",
    "        results.loc[len(results)] = [subset, \"pairwise-comparisons\", score]\n",
    "        # probing\n",
    "        xpath = f\"{PATH}/llmbar-{subset}/{model}/contrast\"\n",
    "        x1 = t.load(f\"{xpath}_1.pt\", weights_only=True).float()\n",
    "        x2 = t.load(f\"{xpath}_2.pt\", weights_only=True).float()\n",
    "        x1 -= x1.mean(0)\n",
    "        x2 -= x2.mean(0)\n",
    "        x = x1 - x2\n",
    "        y = t.tensor(data.labels, dtype=int)\n",
    "        mask = y != -1\n",
    "        x, y = x[mask], y[mask]\n",
    "        perm = t.randperm(len(x))\n",
    "        x, y = x[perm], y[perm]\n",
    "        split_ix = int(0.7*len(x))\n",
    "        x_train, x_test = t.tensor_split(x, [split_ix], dim=0)\n",
    "        y_train, y_test = t.tensor_split(y, [split_ix], dim=0)\n",
    "        # supervised probe\n",
    "        lr = LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            fit_intercept=False,\n",
    "            penalty=\"l2\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=1000,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        lr.fit(x_train, y_train)\n",
    "        preds = lr.predict(x_test)\n",
    "        score = f1_score(y_test, preds, average=\"weighted\", labels=[1, 2])\n",
    "        results.loc[len(results)] = [subset, \"s-probe\", score]\n",
    "        # unsupervised probe\n",
    "        pca = PCA(1)\n",
    "        pca.fit(x_train)\n",
    "        preds = pca.transform(x_test).squeeze(1)\n",
    "        p1 = t.tensor(preds > 0, dtype=t.int64) + 1\n",
    "        p2 = t.tensor(preds < 0, dtype=t.int64) + 1\n",
    "        score = max(\n",
    "            f1_score(y_test, p1, average=\"weighted\", labels=[1, 2]),\n",
    "            f1_score(y_test, p2, average=\"weighted\", labels=[1, 2])\n",
    "        )\n",
    "        results.loc[len(results)] = [subset, \"u-probe\", score]\n",
    "\n",
    "\n",
    "\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # Get unique subsets and methods\n",
    "    subsets = results['subset'].unique()\n",
    "    # Move Normal and Natural to front\n",
    "    subset_list = list(subsets)\n",
    "    for special in ['Natural', 'Normal']:\n",
    "        if special in subset_list:\n",
    "            subset_list.remove(special)\n",
    "    subset_list = ['Normal', 'Natural'] + subset_list\n",
    "    subsets = np.array(subset_list)\n",
    "\n",
    "    methods = ['pairwise-comparisons', 's-probe', 'u-probe']\n",
    "\n",
    "    # Set width of bars and positions of the bars\n",
    "    width = 0.25\n",
    "    x = np.arange(len(subsets))\n",
    "\n",
    "    # Define stronger colors\n",
    "    colors = ['#4a90d4', '#7ac17a', '#e67c73']  # Stronger blue, green, and pink\n",
    "\n",
    "    # Create bars for each method\n",
    "    for i, method in enumerate(methods):\n",
    "        scores = [results[(results['subset'] == subset) & (results['method'] == method)]['f1'].values[0] \n",
    "                for subset in subsets]\n",
    "        plt.bar(x + (i-1)*width, scores, width, label=method, color=colors[i])\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel('Subset')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title(f'{model_titles[model]}: Performance Under Adversarial Prompting')\n",
    "\n",
    "    # Make Normal and Natural labels bold\n",
    "    labels = [f'$\\\\mathbf{{{s}}}$' if s in ['Normal', 'Natural'] else s for s in subsets]\n",
    "    plt.xticks(x, labels, rotation=25, ha='right')\n",
    "    plt.legend()\n",
    "    plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.tight_layout()\n",
    "    path = \"/gws/nopw/j04/ai4er/users/maiush/PPairS/graphs\"\n",
    "    plt.savefig(f\"{path}/llmbar_{model}.png\", dpi=400)\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
