{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from lpaaj.data import TextDataset\n",
    "from lpaaj.constants import LORA_RESULTS_PATH, FULL_RESULTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_keys = {\n",
    "    'newsroom': ['coherence', 'fluency', 'informativeness', 'relevance'],\n",
    "    'summeval': ['coherence', 'consistency', 'fluency', 'relevance'],\n",
    "    'hanna': ['coherence', 'complexity', 'empathy', 'engagement', 'relevance', 'surprise'],\n",
    "    'rocstories': ['consistency']\n",
    "} # default: prompt\n",
    "\n",
    "label_keys = {\n",
    "    'mctaco': 'correct',\n",
    "    'caters': 'first',\n",
    "    'rocstories': 'correct'\n",
    "} # default: prompt-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from /workspace/LP-as-a-Judge/data/newsroom/newsroom_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/newsroom/newsroom_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/newsroom/newsroom_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/newsroom/newsroom_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/newsroom/newsroom_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/newsroom/newsroom_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/newsroom/newsroom_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/newsroom/newsroom_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/summeval/summeval_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/summeval/summeval_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/summeval/summeval_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/summeval/summeval_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/summeval/summeval_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/summeval/summeval_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/summeval/summeval_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/summeval/summeval_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/hanna/hanna_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/hanna/hanna_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/hanna/hanna_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/hanna/hanna_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/hanna/hanna_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/hanna/hanna_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/hanna/hanna_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/hanna/hanna_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/hanna/hanna_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/hanna/hanna_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/hanna/hanna_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/hanna/hanna_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/rocstories/rocstories_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/rocstories/rocstories.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/mctaco/mctaco_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/mctaco/mctaco_pairwise_comparisons.jsonl\n",
      "loading data from /workspace/LP-as-a-Judge/data/caters/caters_prompts_compare.jsonl\n",
      "loading labels from /workspace/LP-as-a-Judge/data/caters/caters_pairwise_comparisons.jsonl\n"
     ]
    }
   ],
   "source": [
    "# === LABELS ===\n",
    "labels = {}\n",
    "datasets = [\"newsroom\", \"summeval\", \"hanna\", \"rocstories\", \"mctaco\", \"caters\"]\n",
    "for dataset in datasets:\n",
    "    pks = prompt_keys.get(dataset, [\"prompt\"])\n",
    "    for pk in pks:\n",
    "        lk = label_keys.get(dataset, pk)\n",
    "        data = TextDataset(\n",
    "            task=\"compare\",\n",
    "            dataset=dataset,\n",
    "            prompt_key=pk,\n",
    "            label_key=lk,\n",
    "        )\n",
    "        labels[f\"{dataset}-{pk}\"] = data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=[\"method\", \"dataset\", \"model\", \"f1\"])\n",
    "for method in [\"lora\", \"full\"]:\n",
    "    for dataset in datasets:\n",
    "        pks = prompt_keys.get(dataset, [\"prompt\"])\n",
    "        RESULTS_PATH = LORA_RESULTS_PATH if method == \"lora\" else FULL_RESULTS_PATH\n",
    "        RESULTS_PATH += f\"/{dataset}\"\n",
    "        models = os.listdir(RESULTS_PATH)\n",
    "        for model in models:\n",
    "            scores = []\n",
    "            for pk in pks:\n",
    "                filepath = f\"{RESULTS_PATH}/{model}/{pk}.pkl\"\n",
    "                with open(filepath, \"rb\") as f: predictions = pickle.load(f)\n",
    "                current_labels = labels[f\"{dataset}-{pk}\"]\n",
    "                score = f1_score(predictions, current_labels, average=\"micro\")\n",
    "                scores.append(score)\n",
    "            results.loc[len(results)] = [method, dataset, model, sum(scores) / len(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results averaged by dataset category:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full</td>\n",
       "      <td>gemma-2-2b-it</td>\n",
       "      <td>0.556953</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>full</td>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>0.597837</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>full</td>\n",
       "      <td>llama-3.1-8b-it</td>\n",
       "      <td>0.557425</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>full</td>\n",
       "      <td>mistral-nemo-12b-it</td>\n",
       "      <td>0.586087</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>full</td>\n",
       "      <td>qwen-2.5-0.5b-it</td>\n",
       "      <td>0.464594</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>full</td>\n",
       "      <td>qwen-2.5-1.5b-it</td>\n",
       "      <td>0.476574</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>full</td>\n",
       "      <td>qwen-2.5-14b-it</td>\n",
       "      <td>0.576812</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>full</td>\n",
       "      <td>qwen-2.5-3b-it</td>\n",
       "      <td>0.553805</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>full</td>\n",
       "      <td>qwen-2.5-7b-it</td>\n",
       "      <td>0.552733</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lora</td>\n",
       "      <td>gemma-2-27b-it</td>\n",
       "      <td>0.582767</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lora</td>\n",
       "      <td>gemma-2-2b-it</td>\n",
       "      <td>0.550121</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lora</td>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>0.588516</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lora</td>\n",
       "      <td>llama-3.1-70b-it</td>\n",
       "      <td>0.580464</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lora</td>\n",
       "      <td>llama-3.1-8b-it</td>\n",
       "      <td>0.558325</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lora</td>\n",
       "      <td>mistral-large-123b-it</td>\n",
       "      <td>0.611523</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lora</td>\n",
       "      <td>mistral-nemo-12b-it</td>\n",
       "      <td>0.583578</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lora</td>\n",
       "      <td>mistral-small-22b-it</td>\n",
       "      <td>0.602981</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-0.5b-it</td>\n",
       "      <td>0.498262</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-1.5b-it</td>\n",
       "      <td>0.504412</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-14b-it</td>\n",
       "      <td>0.578750</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-32b-it</td>\n",
       "      <td>0.586285</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-3b-it</td>\n",
       "      <td>0.554555</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-72b-it</td>\n",
       "      <td>0.594149</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-7b-it</td>\n",
       "      <td>0.541586</td>\n",
       "      <td>text_quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>full</td>\n",
       "      <td>gemma-2-2b-it</td>\n",
       "      <td>0.816158</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>full</td>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>0.910114</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>full</td>\n",
       "      <td>llama-3.1-8b-it</td>\n",
       "      <td>0.813871</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>full</td>\n",
       "      <td>mistral-nemo-12b-it</td>\n",
       "      <td>0.847095</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>full</td>\n",
       "      <td>qwen-2.5-0.5b-it</td>\n",
       "      <td>0.644920</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>full</td>\n",
       "      <td>qwen-2.5-1.5b-it</td>\n",
       "      <td>0.665842</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>full</td>\n",
       "      <td>qwen-2.5-14b-it</td>\n",
       "      <td>0.891381</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>full</td>\n",
       "      <td>qwen-2.5-3b-it</td>\n",
       "      <td>0.720635</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>full</td>\n",
       "      <td>qwen-2.5-7b-it</td>\n",
       "      <td>0.813316</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lora</td>\n",
       "      <td>gemma-2-27b-it</td>\n",
       "      <td>0.899538</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>lora</td>\n",
       "      <td>gemma-2-2b-it</td>\n",
       "      <td>0.774253</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>lora</td>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>0.902166</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>lora</td>\n",
       "      <td>llama-3.1-70b-it</td>\n",
       "      <td>0.905352</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>lora</td>\n",
       "      <td>llama-3.1-8b-it</td>\n",
       "      <td>0.833218</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>lora</td>\n",
       "      <td>mistral-large-123b-it</td>\n",
       "      <td>0.926225</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>lora</td>\n",
       "      <td>mistral-nemo-12b-it</td>\n",
       "      <td>0.814910</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lora</td>\n",
       "      <td>mistral-small-22b-it</td>\n",
       "      <td>0.903250</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-0.5b-it</td>\n",
       "      <td>0.696704</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-1.5b-it</td>\n",
       "      <td>0.754536</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-14b-it</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-32b-it</td>\n",
       "      <td>0.903340</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-3b-it</td>\n",
       "      <td>0.775912</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-72b-it</td>\n",
       "      <td>0.903433</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>lora</td>\n",
       "      <td>qwen-2.5-7b-it</td>\n",
       "      <td>0.862792</td>\n",
       "      <td>common_sense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   method                  model        f1      category\n",
       "0    full          gemma-2-2b-it  0.556953  text_quality\n",
       "1    full          gemma-2-9b-it  0.597837  text_quality\n",
       "2    full        llama-3.1-8b-it  0.557425  text_quality\n",
       "3    full    mistral-nemo-12b-it  0.586087  text_quality\n",
       "4    full       qwen-2.5-0.5b-it  0.464594  text_quality\n",
       "5    full       qwen-2.5-1.5b-it  0.476574  text_quality\n",
       "6    full        qwen-2.5-14b-it  0.576812  text_quality\n",
       "7    full         qwen-2.5-3b-it  0.553805  text_quality\n",
       "8    full         qwen-2.5-7b-it  0.552733  text_quality\n",
       "9    lora         gemma-2-27b-it  0.582767  text_quality\n",
       "10   lora          gemma-2-2b-it  0.550121  text_quality\n",
       "11   lora          gemma-2-9b-it  0.588516  text_quality\n",
       "12   lora       llama-3.1-70b-it  0.580464  text_quality\n",
       "13   lora        llama-3.1-8b-it  0.558325  text_quality\n",
       "14   lora  mistral-large-123b-it  0.611523  text_quality\n",
       "15   lora    mistral-nemo-12b-it  0.583578  text_quality\n",
       "16   lora   mistral-small-22b-it  0.602981  text_quality\n",
       "17   lora       qwen-2.5-0.5b-it  0.498262  text_quality\n",
       "18   lora       qwen-2.5-1.5b-it  0.504412  text_quality\n",
       "19   lora        qwen-2.5-14b-it  0.578750  text_quality\n",
       "20   lora        qwen-2.5-32b-it  0.586285  text_quality\n",
       "21   lora         qwen-2.5-3b-it  0.554555  text_quality\n",
       "22   lora        qwen-2.5-72b-it  0.594149  text_quality\n",
       "23   lora         qwen-2.5-7b-it  0.541586  text_quality\n",
       "24   full          gemma-2-2b-it  0.816158  common_sense\n",
       "25   full          gemma-2-9b-it  0.910114  common_sense\n",
       "26   full        llama-3.1-8b-it  0.813871  common_sense\n",
       "27   full    mistral-nemo-12b-it  0.847095  common_sense\n",
       "28   full       qwen-2.5-0.5b-it  0.644920  common_sense\n",
       "29   full       qwen-2.5-1.5b-it  0.665842  common_sense\n",
       "30   full        qwen-2.5-14b-it  0.891381  common_sense\n",
       "31   full         qwen-2.5-3b-it  0.720635  common_sense\n",
       "32   full         qwen-2.5-7b-it  0.813316  common_sense\n",
       "33   lora         gemma-2-27b-it  0.899538  common_sense\n",
       "34   lora          gemma-2-2b-it  0.774253  common_sense\n",
       "35   lora          gemma-2-9b-it  0.902166  common_sense\n",
       "36   lora       llama-3.1-70b-it  0.905352  common_sense\n",
       "37   lora        llama-3.1-8b-it  0.833218  common_sense\n",
       "38   lora  mistral-large-123b-it  0.926225  common_sense\n",
       "39   lora    mistral-nemo-12b-it  0.814910  common_sense\n",
       "40   lora   mistral-small-22b-it  0.903250  common_sense\n",
       "41   lora       qwen-2.5-0.5b-it  0.696704  common_sense\n",
       "42   lora       qwen-2.5-1.5b-it  0.754536  common_sense\n",
       "43   lora        qwen-2.5-14b-it  0.896594  common_sense\n",
       "44   lora        qwen-2.5-32b-it  0.903340  common_sense\n",
       "45   lora         qwen-2.5-3b-it  0.775912  common_sense\n",
       "46   lora        qwen-2.5-72b-it  0.903433  common_sense\n",
       "47   lora         qwen-2.5-7b-it  0.862792  common_sense"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_quality_datasets = [\"newsroom\", \"summeval\", \"hanna\"]\n",
    "common_sense_datasets = [\"mctaco\", \"caters\", \"rocstories\"]\n",
    "\n",
    "# Group by dataset categories and average F1 scores\n",
    "text_quality_results = results[results['dataset'].isin(text_quality_datasets)].groupby(['method', 'model'])['f1'].mean().reset_index()\n",
    "text_quality_results['category'] = 'text_quality'\n",
    "\n",
    "common_sense_results = results[results['dataset'].isin(common_sense_datasets)].groupby(['method', 'model'])['f1'].mean().reset_index()\n",
    "common_sense_results['category'] = 'common_sense'\n",
    "\n",
    "# Combine the results\n",
    "category_results = pd.concat([text_quality_results, common_sense_results], ignore_index=True)\n",
    "print(\"Results averaged by dataset category:\")\n",
    "category_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_results.to_json(f\"/workspace/PPairS_results/finetuning_results.jsonl\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
